import lxml
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import pandas as pd
import seaborn as sn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn import datasets, svm
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.preprocessing import OneHotEncoder
from xgboost import XGBClassifier
import sweetviz

from sklearn.compose import make_column_transformer


COLUMN_TARGET = 'result'

'''
xl_file = pd.read_excel('permissions.xlsx', sheet_name=None)

ds_begnin = xl_file['Begnin']
ds_malware = xl_file['Malware']

ds_begnin[COLUMN_TARGET] = '0'
ds_malware[COLUMN_TARGET] = '1'


frames = [ds_begnin, ds_malware]
df = pd.concat(frames)

print(ds_begnin.shape)
print(ds_malware.shape)
print(df.shape)

df.to_csv('file_name.csv', index=False)
'''


def analyze(train) :
    my_report = sweetviz.analyze([train, "Train"], target_feat='result')
    my_report.show_html('Report.html')

df = pd.read_csv('malware-dataset/file_name.csv')

analyze(df)

print(df.shape)

print(df.isna())
print(df.info())
print(df.describe())

balance = df.groupby(COLUMN_TARGET).count()
print(balance)

unique = df.Category.unique()
print(unique)

new_df = df.groupby(COLUMN_TARGET).apply(lambda x: x.sample(n=9999)).reset_index(drop=True)
balance = new_df.groupby(COLUMN_TARGET).count()
print(balance)
#df = new_df


df = pd.concat([df, pd.get_dummies(df['Category'], prefix='Category', drop_first=True)], axis=1)
df.drop(['Category'],axis=1, inplace=True)

df = df[[c for c in df if c not in [COLUMN_TARGET]] + [COLUMN_TARGET]]

print(df.shape)
print(df.head(10))
print(df.columns.values)



'''
corrmat = df.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(20, 20))
g = sns.heatmap(df[top_corr_features].corr(), annot=True,cmap="RdYlGn")
plt.show()

df.hist()
plt.show()

'''

#ds.to_csv('csvfile.csv', encoding='utf-8', index=False)

#print(dataset.head())

#.values.astype(int)
X = df.iloc[:, 1:-1]
y = df.iloc[:, -1]



def plot_correlation_target(data_frame, target_column_name):
    #copy dataframe
    data_frame_without_target = data_frame.copy()
    #drop target column as we do not need for the correlation plot
    data_frame_without_target.drop([target_column_name], axis=1, inplace=True)

    data_frame_without_target.corrwith(data_frame[COLUMN_TARGET]).plot.barh(
        figsize=(15, 150), title='Correlation with result',
        fontsize=15, grid=True)
    plt.show()

plot_correlation_target(df.copy(), COLUMN_TARGET)

sns.countplot(df[COLUMN_TARGET], label='Count')
plt.show()




## Univariate Selection
best_features = SelectKBest(score_func=chi2, k=10)
fit = best_features.fit(X, y)

df_scores = pd.DataFrame(fit.scores_)
df_columns = pd.DataFrame(X.columns)


print(df_scores)
print(df_columns)


feature_scores = pd.concat([df_columns, df_scores], axis=1)
feature_scores.columns = ['Specs', 'Score']

print(feature_scores)


print(feature_scores.nlargest(10, 'Score'))



## Feature Importance

model = ExtraTreesClassifier()
model.fit(X, y)
print(model.feature_importances_)

feat_importances = pd.Series(model.feature_importances_, index=X.columns)
feat_importances.nlargest(25).plot(kind='barh')
plt.show()



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=40)

'''
tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},
                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},
                    {'kernel': ['poly'], 'C': [1, 10, 100, 1000]},
                    {'kernel': ['sigmoid'], 'C': [1, 10, 100, 1000]}]

scores = ['precision', 'recall']

for score in scores:
    print("# Tuning hyper-parameters for %s" % score)
    print()

    clf = GridSearchCV(
        SVC(), tuned_parameters, scoring='%s_macro' % score, n_jobs=-1, verbose=10
    )
    clf.fit(X_train, y_train)

    print("Best parameters set found on development set:")
    print()
    print(clf.best_params_)
    print()
    print("Grid scores on development set:")
    print()
    means = clf.cv_results_['mean_test_score']
    stds = clf.cv_results_['std_test_score']
    for mean, std, params in zip(means, stds, clf.cv_results_['params']):
        print("%0.3f (+/-%0.03f) for %r"
              % (mean, std * 2, params))
    print()

    print("Detailed classification report:")
    print()
    print("The model is trained on the full development set.")
    print("The scores are computed on the full evaluation set.")
    print()
    y_true, y_pred = y_test, clf.predict(X_test)
    print(classification_report(y_true, y_pred))
    print()

'''

#classifier = SVC(kernel='poly', random_state=42, C=10)
classifier = XGBClassifier()

#score = cross_val_score(classifier, X, y,  cv=10)
#print(score.mean())

classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)

conf = confusion_matrix(y_test, y_pred)

df_cm = pd.DataFrame(conf, range(2), range(2))
#plt.figure(figsize=(10, 7))
sn.set(font_scale=1.4) # for label size
sn.heatmap(df_cm, annot=True, annot_kws={"size": 16}, fmt='g') # font size
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
plt.savefig('cm.png')

print(conf)


