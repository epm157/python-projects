# -*- coding: utf-8 -*-
"""Data Validation with TensorFlow Data Validation (TFDV).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tx6I0iEzGrCesuBaum5VWkUI8sKWZeEP

## Stage 1: Install all dependencies and setting up the environment
"""

!apt-get install python-dev python-snappy

!pip install -q tensorflow_data_validation

"""## Stage 2: Import project dependencies"""

import pandas as pd
import tensorflow as tf
import tensorflow_data_validation as tfdv

from __future__ import print_function

"""## Stage 3: Simple dataset analysis"""

dataset = pd.read_csv("pollution_small.csv")

dataset.shape

training_data = dataset[:1600]

training_data.describe()

test_set = dataset[1600:]

test_set.describe()

"""## Stage 3: Data analysis and validation with TFDV

### Generate training data statistics
"""

train_stats = tfdv.generate_statistics_from_dataframe(dataframe=dataset)

"""### Infering the schema"""

schema = tfdv.infer_schema(statistics=train_stats)

tfdv.display_schema(schema)

"""### Calculate test set statistics"""

test_stats = tfdv.generate_statistics_from_dataframe(dataframe=test_set)

"""## Stage 4: Compare test statistics with the Schema

### Checking for anomalies in new data
"""

anomalies = tfdv.validate_statistics(statistics=test_stats, schema=schema)

"""### Displaying all detected anomalies

- Integer larger than 10
- STRING type when expected INT type
- FLOAT type when expected INT type
- Integer smaller than 0
"""

tfdv.display_anomalies(anomalies)

"""### New data WITH anomalies"""

test_set_copy = test_set.copy()

test_set_copy.drop("soot", axis=1, inplace=True)

"""### Statistics based on data with anomalies"""

test_set_copy_stats = tfdv.generate_statistics_from_dataframe(dataframe=test_set_copy)

anomalies_new = tfdv.validate_statistics(statistics=test_set_copy_stats, schema=schema)

tfdv.display_anomalies(anomalies_new)

"""## Stage 5: Prepare the schema for Serving"""

schema.default_environment.append("TRAINING")
schema.default_environment.append("SERVING")

"""### Removing a target column from the Serving schema"""

tfdv.get_feature(schema, "soot").not_in_environment.append("SERVING")

"""### Checking for anomalies between the SERVING environment and new test set"""

serving_env_anomalies = tfdv.validate_statistics(test_set_copy_stats, schema, environment="SERVING")

tfdv.display_anomalies(serving_env_anomalies)

